Ex 1:

n = 4
alpha = 1.

# SCRIVERE QUI SOTTO IL CODICE DELL'ESERCIZIO
################

# Aggiungiamo un punto a x

x3 = ... # np.array([x2[0, 0], x2[1, 0], 0.5])[:, np.newaxis]
y3 = ... # np.array([y2[0, 0], y2[1, 0], 6.5])[:, np.newaxis]


# Creiamo la matrice dei dati X3
X3 = ... # np.concatenate((x3**4, x3**3, x3**2, x3**1, x3**0),1)

# Applichiamo la formula della ridge regression
theta3 = ... # np.linalg.inv(X3.T @ X3 + 1. * np.eye(5)) @ X3.T @ y3

# Valutiamo il nuovo modello in alcuni punti
x3_new = ... # np.linspace(-2, 2, 20)[:, np.newaxis]
X3_new = ... # np.concatenate((x3_new**4, x3_new**3, x3_new**2, x3_new**1, x3_new**0),1)
y3_new = ... # X3_new@theta3  

# Plottiamo il nuovo modello (e confrontiamo con il modello fittato con 2 punti)
# plt.scatter(x2_new, y2_new)
# plt.scatter(x2, y2, color='r')
# plt.legend(['Model', 'Data'])
# plt.xlim(-2, 2)
# plt.ylim(-15, 15)
# plt.title('Ridge regression n = 4 con 2 punti (alpha = 1)')

# plt.figure()
# plt.scatter(x3_new, y3_new)
# plt.scatter(x3, y3, color='r')
# plt.legend(['Model', 'Data'])
# plt.xlim(-2, 2)
# plt.ylim(-15, 15)
# plt.title('Ridge regression n = 4 con 3 punti (alpha = 1)')

# Effettuiamo la regressione regolarizzata per diversi valori di alpha
for alpha_i in [0.1, 0.5, 10., 100.]:
  theta = ... # np.linalg.inv(X3.T @ X3 + alpha_i * np.eye(5)) @ X3.T @ y3
  # Stampiamo i valori di theta e la relativa norma
  print(...) # print(f"theta = {theta}")
  print(...) # print(f"np.linalg.norm(theta) = {np.linalg.norm(theta)}")
  
  # valutiamo il modello nei nuovi punti
  y_new = ... # X3_new@theta
  
  # plt.figure()
  # plt.scatter(x3_new, y_new)
  # plt.scatter(x3, y3, color='r')
  # plt.legend(['Model', 'Data'])
  # plt.xlim(-2, 2)
  # plt.ylim(-15, 15)
  # plt.title(f"Ridge regression n = 4 con 3 punti (alpha = {alpha_i})")
  
  
   
  

Ex 2:

n = 100
sigma_square = 10.
alpha = 5.
drums_small_chunk = drums_long[:n]

# SCRIVERE QUI SOTTO IL CODICE DELL'ESERCIZIO
################

# L'equazione normale e' la seguente:
# x = (I^T@I + alpha D^TD)^-1 I^T x_noisy
# x = (I + alpha D^T D) x_noisy
(Usare Eq. 85 del matrix cookbook)

# Perturbiamo drums_chunk con rumore Gaussiano
# Campioniamo una z (usare np.random.randn e moltiplicare per sigma**2)
z = sigma_square*np.random.randn((drums_small_chunk.shape[0]))[:, np.newaxis]
x_noisy =  drums_small_chunk + z

plt.figure()
y_plot = x_noisy
x_plot = np.arange(y_plot.shape[0])
plot(x_plot, y_plot, title="Segnale noisy ($\\sigma^2 = 10$)")

plt.figure()
y_plot = drums_small_chunk
x_plot = np.arange(y_plot.shape[0])
plot(x_plot, y_plot, title="Segnale originale")

# Scriviamo l'operatore D (conviene usare sparse.diags, poi passare alla matrice densa)
	D = sparse.diags([1, -1], [0, 1], shape=(n, n)).toarray()

# Risolviamo per la x
x = np.linalg.inv(np.eye(x_noisy.shape[0]) - alpha * D.T@D) @ x_noisy

# Plottiamo la soluzione x:
plt.figure()
y_plot = x
x_plot = np.arange(y_plot.shape[0])
plot(x_plot, y_plot, title="Segnale ricostruito ($\\alpha = 5, \\sigma^2 = 10$)")

# Risolviamo su tutto drums
z = (sigma_square**2)*np.random.randn(drums_long.shape[0], 1)
drums_long_noisy = drums_long + z

# IPython.display.Audio(drums_long[:, 0], rate=sr)
# IPython.display.Audio(drums_long_noisy[:, 0], rate=sr)

x_long = np.zeros((88200,1))
# print(drums_long_noisy.shape)

for i in range(88200 // n):
  x_noisy_local = drums_long_noisy[i*n: (i+1)*n,:]
  x_local = np.linalg.inv(np.eye(n) - alpha * D.T@D) @ x_noisy_local
  x_long[i*n:(i+1)*n] = x_local

# IPython.display.Audio(x_long[:, 0], rate=sr)






Ex 3:


# SCRIVERE QUI SOTTO IL CODICE DELL'ESERCIZIO
################

# carichiamo l'imagine con PIL
image = ... # Image.open('mountain.png')
# trasformiamo in un vettore np dopo aver normalizzato
pix = ... # np.array(image) / np.max(np.array(image))

# plottiamo l'immagine
# plt.imshow(pix)

# creare rumore e aggiungere al dato
z = ... # sigma_square*np.random.randn(pix.shape[0], pix.shape[1],3)
x_noisy =  ... # pix + z
# x_noisy = np.clip(x_noisy, 0., 1.)

# plottiamo l'immagine noisy
# plt.imshow(x_noisy)

# la soluzione
x = ... #np.zeros((n, n, 3))
# kernel di derivazione su chunk
D = ... #sparse.diags([1, -1], [0, 1],
        #         shape=(chunk_size**2, chunk_size**2)).toarray()

# iteriamo sui diversi chunk e applichiamo il denoising su ognuno di loro
for i_chunk in range(n // chunk_size):
  for j_chunk in tqdm(range(n // chunk_size)):
    # indicizziamo il chunk noisy
    patch_noisy = ...# x_noisy[i_chunk*chunk_size:(i_chunk+1)*chunk_size,
                     #        j_chunk*chunk_size:(j_chunk+1)*chunk_size]
    # trasformiamo il chunk in un vettore
    patch_noisy_vec = ...  # patch_noisy.reshape(chunk_size**2, 3)
    # iteriamo sui 3 canali
    for c in range(3):
      # applichiamo le equazioni normali con la loss L2 sulla derivata
      # (ricordarsi di effettuare il clipping per evitare valori oltre il boundary [0., 1.])
      patch_rec_tmp = ... # np.clip((np.linalg.inv(np.eye(patch_noisy_vec.shape[0]) +
                          #                   alpha * (D.T@D)) @ patch_noisy_vec[:, c]), 0., 1.)
      # riempire il valore di x con le generazioni locali
      x[i_chunk*chunk_size:(i_chunk+1)*chunk_size,
        j_chunk*chunk_size:(j_chunk+1)*chunk_size, c] = ... # patch_rec_tmp.reshape(chunk_size, chunk_size)
